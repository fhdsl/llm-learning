<!-- Generated by SpecStory -->

# Interacting with the llm package overview (2025-05-15 10:15:45)

_**User**_

Summarize the different ways to interact with the llm package: https://github.com/simonw/llm

---

_**Assistant**_

Here's a summary of the main ways to interact with the `llm` package:

### Command Line Interface
````bash
# Basic prompt
llm "What is the capital of France?"

# Using a specific model
llm -m gpt-4 "Explain quantum computing"

# Chat mode
llm chat

# Processing files
llm "Summarize this:" < input.txt
````

### Python API
````python
import llm

# Simple completion
response = llm.complete("What is the capital of France?")

# Specify model
response = llm.complete("Explain quantum computing", model="gpt-4")

# Chat conversation
conversation = llm.chat()
response = conversation.send("Hello")
````

### Key Features
- **Multiple Model Support**: OpenAI, Anthropic, local models
- **System Prompts**: Set default behaviors
- **Conversation History**: Save and load chat sessions
- **Plugins**: Extend functionality
- **Templates**: Create reusable prompt templates
- **Logging**: Track usage and responses

### Configuration
````bash
# Set API keys
llm keys set openai
llm keys set anthropic

# List available models
llm models list
````

For more details, you can check the [official documentation](https://llm.datasette.io/en/stable/).

---

_**User**_

How do I install this package?

---

_**Assistant**_

Let me add the installation instructions to the document:

````markdown
# Interacting with the llm package overview (2025-05-15 10:15:45)

### Installation

```bash
# Basic installation
pip install llm

# Install with all optional dependencies
pip install llm[all]

# Install specific providers
pip install llm[openai]    # For OpenAI support
pip install llm[anthropic] # For Anthropic support
```

After installation, you'll need to configure your API keys:
```bash
llm keys set openai
llm keys set anthropic
```

// ...existing code...
````

The installation requires Python 3.7 or higher. If you're using multiple Python versions, you might want to use a virtual environment:

````bash
# Create and activate a virtual environment
python -m venv venv
source venv/bin/activate  # On Mac/Linux
````

After installation, you can verify it's working by running:
````bash
llm --version
````

---

_**User**_

Write a requirements.txt for installing this package

---

_**Assistant**_

Here's a `requirements.txt` file with different installation options:

````plaintext
# Basic installation
llm>=0.12.0

# Optional: Install all providers and features
# Uncomment the following line instead of the basic installation
# llm[all]>=0.12.0

# Optional: Individual providers
# Uncomment the ones you need
# llm[openai]>=0.12.0     # For OpenAI support
# llm[anthropic]>=0.12.0  # For Anthropic/Claude support
# llm[replicate]>=0.12.0  # For Replicate.com models
````

Save this file in your project root directory. Then install using:

```bash
pip install -r requirements.txt
```

---

